{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-03T10:41:17.656383Z",
     "iopub.status.busy": "2024-09-03T10:41:17.655860Z",
     "iopub.status.idle": "2024-09-03T10:41:34.129110Z",
     "shell.execute_reply": "2024-09-03T10:41:34.128181Z",
     "shell.execute_reply.started": "2024-09-03T10:41:17.656352Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow tensorflow-addons datasets transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import opendatasets as od\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications import EfficientNetB2, InceptionV3\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Dense, Flatten, Concatenate, BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od.download(\n",
    "    \"/kaggle/input/breast-mammography-private\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:41:34.131216Z",
     "iopub.status.busy": "2024-09-03T10:41:34.130945Z",
     "iopub.status.idle": "2024-09-03T10:42:02.376894Z",
     "shell.execute_reply": "2024-09-03T10:42:02.375985Z",
     "shell.execute_reply.started": "2024-09-03T10:41:34.131191Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = (224, 224)\n",
    "train_dir = \"/kaggle/input/breast-mammography-private/train\"\n",
    "\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "# Define the label mapping\n",
    "label_map = {0: \"NORMAL\", 1: \"ABNORMAL\"}\n",
    "\n",
    "# Collect 5 images for each class\n",
    "images_by_class = {0: [], 1: []}\n",
    "\n",
    "for image, label in train_dataset.unbatch().take(1000):  # Increase the range if necessary\n",
    "    label_value = label.numpy()\n",
    "    if len(images_by_class[label_value]) < 5:\n",
    "        images_by_class[label_value].append((image, label))\n",
    "    if all(len(images) >= 5 for images in images_by_class.values()):\n",
    "        break\n",
    "\n",
    "# Combine the images and labels\n",
    "images_to_plot = []\n",
    "for class_images in images_by_class.values():\n",
    "    images_to_plot.extend(class_images)\n",
    "\n",
    "# Display the images\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i, (img, lbl) in enumerate(images_to_plot):\n",
    "    plt.subplot(4, 5, i + 1)  # 4 rows, 5 columns\n",
    "    plt.imshow(img.numpy().astype(\"uint8\"))\n",
    "    label = lbl.numpy()\n",
    "    plt.title(f\"{label_map[label]} ({label}), Size: {img.shape}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:42:02.378336Z",
     "iopub.status.busy": "2024-09-03T10:42:02.378051Z",
     "iopub.status.idle": "2024-09-03T10:42:04.509819Z",
     "shell.execute_reply": "2024-09-03T10:42:04.508900Z",
     "shell.execute_reply.started": "2024-09-03T10:42:02.378311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = (224, 224)\n",
    "PATCH_SIZE = 16\n",
    "NUM_CLASSES = 2\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 3e-4  # Adjusted learning rate\n",
    "\n",
    "# Load the dataset\n",
    "train_dir = \"/kaggle/input/breast-mammography-private/train\"\n",
    "test_dir = \"/kaggle/input/breast-mammography-private/test\"\n",
    "\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Preprocess the dataset\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(40 / 360),  # Convert degrees to fraction\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomTranslation(0.2, 0.2),  # width_shift_range and height_shift_range\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:42:04.513165Z",
     "iopub.status.busy": "2024-09-03T10:42:04.512731Z",
     "iopub.status.idle": "2024-09-03T10:42:15.385354Z",
     "shell.execute_reply": "2024-09-03T10:42:15.384566Z",
     "shell.execute_reply.started": "2024-09-03T10:42:04.513132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained models without the top layers\n",
    "MobileNet_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "DenseNet_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Set trainable to False to freeze the pre-trained layers\n",
    "MobileNet_model.trainable = False\n",
    "DenseNet_model.trainable = False\n",
    "VGG_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T10:46:35.408464Z",
     "iopub.status.busy": "2024-09-03T10:46:35.407711Z",
     "iopub.status.idle": "2024-09-03T10:46:37.835713Z",
     "shell.execute_reply": "2024-09-03T10:46:37.834792Z",
     "shell.execute_reply.started": "2024-09-03T10:46:35.408429Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MultiHeadAttention\n",
    "\n",
    "def multihead_attention_layer(inputs, num_heads=4, key_dim=64):\n",
    "    # Expand dimensions to add a sequence length of 1\n",
    "    expanded_inputs = tf.expand_dims(inputs, axis=1)\n",
    "    \n",
    "    # Apply multi-head attention\n",
    "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(expanded_inputs, expanded_inputs)\n",
    "    \n",
    "    # Squeeze the sequence length back to the original shape\n",
    "    attention_output = tf.squeeze(attention_output, axis=1)\n",
    "\n",
    "def create_ensemble_model(input_shape, num_classes):\n",
    "    # Inputs\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Data augmentation\n",
    "    augmented = data_augmentation(inputs)\n",
    "\n",
    "    # MobileNet model\n",
    "    mobilenet_output = MobileNet_model(augmented)\n",
    "    print(f\"mobilenet_output: {mobilenet_output.shape}\")\n",
    "    mobilenet_output = layers.GlobalAveragePooling2D()(mobilenet_output)\n",
    "    print(mobilenet_output.shape)\n",
    "\n",
    "    # DenseNet model\n",
    "    densenet_output = DenseNet_model(augmented)\n",
    "    print(f\"densenet_output: {densenet_output.shape}\")\n",
    "    densenet_output = layers.GlobalAveragePooling2D()(densenet_output)\n",
    "    print(densenet_output.shape)\n",
    "\n",
    "    # VGG model\n",
    "    vgg_output = VGG_model(augmented)\n",
    "    print(f\"vgg_output: {vgg_output.shape}\")\n",
    "    vgg_output = layers.GlobalAveragePooling2D()(vgg_output)\n",
    "    print(vgg_output.shape)\n",
    "\n",
    "    # Concatenate outputs\n",
    "    concatenated = layers.Concatenate()([mobilenet_output, densenet_output, vgg_output])\n",
    "\n",
    "    # Apply attention layer\n",
    "    attention_output = attention_layer(concatenated)\n",
    "    print(f\"attention_output: {attention_output.shape}\")\n",
    "    \n",
    "    # Dense layers after concatenation\n",
    "    x = layers.BatchNormalization()(attention_output)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    print(outputs.shape)\n",
    "    \n",
    "    # Create model\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T11:28:04.891036Z",
     "iopub.status.busy": "2024-09-03T11:28:04.890657Z",
     "iopub.status.idle": "2024-09-03T11:53:35.063294Z",
     "shell.execute_reply": "2024-09-03T11:53:35.062316Z",
     "shell.execute_reply.started": "2024-09-03T11:28:04.891008Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# Callbacks for early stopping, reducing learning rate, and saving the best model\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"/kaggle/working/model/best_model.keras\",\n",
    "    save_best_only=True,\n",
    "    monitor=\"val_sparse_categorical_accuracy\",\n",
    "    mode=\"max\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_dataset,\n",
    "    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T11:54:20.853893Z",
     "iopub.status.busy": "2024-09-03T11:54:20.853475Z",
     "iopub.status.idle": "2024-09-03T11:54:57.411170Z",
     "shell.execute_reply": "2024-09-03T11:54:57.410165Z",
     "shell.execute_reply.started": "2024-09-03T11:54:20.853860Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Assuming 'model' and 'test_dataset' are already defined\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Get predictions and true labels\n",
    "y_pred = []\n",
    "y_true = []\n",
    "y_prob = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    predictions = model.predict(images)\n",
    "    y_pred.extend(tf.argmax(predictions, axis=1).numpy())\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_prob.extend(predictions)\n",
    "\n",
    "# Define target names for the classification report\n",
    "target_names = ['NORMAL', 'ABNORMAL']\n",
    "\n",
    "# Calculate and print the classification report\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "# Calculate precision, recall, F1 score using sklearn\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Calculate AUC-ROC score\n",
    "y_true_one_hot = tf.keras.utils.to_categorical(y_true, num_classes=2)\n",
    "auc_roc = roc_auc_score(y_true_one_hot, y_prob, average='weighted', multi_class='ovr')\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'AUC-ROC: {auc_roc:.2f}')\n",
    "print(f'AUC-ROC: {auc_roc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T11:55:06.579982Z",
     "iopub.status.busy": "2024-09-03T11:55:06.579399Z",
     "iopub.status.idle": "2024-09-03T11:55:06.588320Z",
     "shell.execute_reply": "2024-09-03T11:55:06.587266Z",
     "shell.execute_reply.started": "2024-09-03T11:55:06.579948Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_test_images = len(test_dataset) * BATCH_SIZE\n",
    "\n",
    "# Count the number of samples for each class\n",
    "normal_count = np.sum(np.array(y_true) == 0)\n",
    "abnormal_count = np.sum(np.array(y_true) == 1)\n",
    "\n",
    "# Print the counts for each class\n",
    "print(f'Number of Normal samples: {normal_count}')\n",
    "print(f'Number of Abnormal samples: {abnormal_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T11:55:09.748129Z",
     "iopub.status.busy": "2024-09-03T11:55:09.747770Z",
     "iopub.status.idle": "2024-09-03T11:55:10.222560Z",
     "shell.execute_reply": "2024-09-03T11:55:10.221297Z",
     "shell.execute_reply.started": "2024-09-03T11:55:09.748102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['sparse_binary_accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_sparse_binary_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1592399,
     "sourceId": 2619910,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
